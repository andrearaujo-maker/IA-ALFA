# bot_ia_popbra.py
# Bot Telegram individual com IA probabilÃ­stica adaptativa (simulaÃ§Ã£o por padrÃ£o)
# Requisitos: requests
# Rodar: python bot_ia_popbra.py

import requests
import threading
import time
import json
import os
from collections import defaultdict, Counter

# ---------------- CONFIG ----------------
TELEGRAM_TOKEN = "8126373920:AAEdRJ48gNqflX-M3kcihod4xegf314iup0"  # seu token (guarde seguro)
TELEGRAM_API = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
USE_REAL_API = True   # False = usa dados simulados; True = buscar a API real (cuidado com CORS/limites)
API_URL = "https://draw.ar-lottery01.com/WinGo/WinGo_30S/GetHistoryIssuePage.json"
FETCH_INTERVAL = 5     # segundos
LOOKBACK_MAX = 200
ANALYZE_WINDOW_SIZES = [3,4,5,6]
PERSIST_FILE = "aprendizado_bot.json"
# ----------------------------------------

# Estado em memÃ³ria
numeric_history = []   # lista de ints (oldest->newest)
gp_history = []        # list of 'G'/'P'
last_issue = None
signals = []           # lista de dicts de sinais gerados (opcional)
subscribers = {}       # chat_id -> {last_sent: 'G'/'P' or None}
stats = {"total":0, "correct":0, "accuracy":0.0}

# Persistence helpers
def load_state():
    global subscribers, signals, stats
    if os.path.exists(PERSIST_FILE):
        try:
            with open(PERSIST_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            subscribers = {int(k):v for k,v in data.get("subscribers", {}).items()}
            signals = data.get("signals", [])
            stats.update(data.get("stats", {}))
            print("[state] carregado", PERSIST_FILE)
        except Exception as e:
            print("[state] falha ao carregar:", e)

def save_state():
    try:
        with open(PERSIST_FILE, "w", encoding="utf-8") as f:
            obj = {
                "subscribers": subscribers,
                "signals": signals[-1000:],
                "stats": stats
            }
            json.dump(obj, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print("[state] falha ao salvar:", e)

# ---------------- Telegram helpers ----------------
def telegram_send_message(chat_id, text):
    url = f"{TELEGRAM_API}/sendMessage"
    payload = {"chat_id": chat_id, "text": text}
    try:
        r = requests.post(url, json=payload, timeout=8)
        return r.ok
    except Exception as e:
        print("[tg] send error:", e)
        return False

# Simple getUpdates loop to detect /start and /stop
last_update_id = None
def telegram_updates_loop():
    global last_update_id
    print("[tg] iniciando loop de updates (use /start para se registrar)")
    while True:
        try:
            url = f"{TELEGRAM_API}/getUpdates"
            params = {"timeout": 10}
            if last_update_id:
                params["offset"] = last_update_id + 1
            r = requests.get(url, params=params, timeout=15)
            if r.status_code == 200:
                data = r.json()
                if data.get("ok"):
                    for item in data.get("result", []):
                        last_update_id = item["update_id"]
                        # handle message
                        msg = item.get("message") or item.get("edited_message")
                        if not msg:
                            continue
                        chat_id = msg["chat"]["id"]
                        text = msg.get("text","").strip()
                        if text.startswith("/start"):
                            subscribers[chat_id] = {"last_sent": None}
                            save_state()
                            telegram_send_message(chat_id, "âœ… Registrado! VocÃª receberÃ¡ o Ãºltimo sinal automÃ¡tico (enviaremos apenas novos sinais).")
                            # send immediate last prediction if exists
                            if gp_history:
                                pred, conf, next_issue = current_prediction_payload()
                                send_prediction_to_chat(chat_id, pred, conf, next_issue)
                        elif text.startswith("/stop"):
                            if chat_id in subscribers:
                                del subscribers[chat_id]
                                save_state()
                            telegram_send_message(chat_id, "ðŸ›‘ VocÃª foi desregistrado. Envie /start para receber sinais novamente.")
                        elif text.startswith("/status"):
                            # quick status
                            pred, conf, next_issue = current_prediction_payload()
                            st = f"Status:\nPrÃ³ximo PerÃ­odo: {next_issue}\nPrÃ³ximo Sinal: {'ðŸŸ  Grande' if pred=='G' else 'ðŸ”µ Pequeno' if pred=='P' else '-'}\nConfianÃ§a: {conf}%\nAssinantes: {len(subscribers)}\nAcertos: {stats.get('correct',0)} / {stats.get('total',0)}  ({stats.get('accuracy',0)}%)"
                            telegram_send_message(chat_id, st)
                        # else ignore other messages
        except Exception as e:
            print("[tg] updates loop error:", e)
            time.sleep(2)

# helper to format and send prediction
def send_prediction_to_chat(chat_id, prediction, confidence, next_issue):
    if prediction not in ('G','P'):
        return
    # only send if different from last sent to this chat_id
    last = subscribers.get(chat_id, {}).get("last_sent")
    if last == prediction:
        return False
    text = (
        "ðŸŽ¯ Sinal AutomÃ¡tico\n"
        f"ðŸ”® PrÃ³xima Entrada: {'ðŸŸ  Grande' if prediction=='G' else 'ðŸ”µ Pequeno'}\n"
        f"ðŸ“… PerÃ­odo: {next_issue}\n"
        f"ðŸ¤– ConfianÃ§a: {confidence}%\n\n"
        "ðŸ”” Para parar de receber: /stop"
    )
    ok = telegram_send_message(chat_id, text)
    if ok:
        # update last_sent and persist
        subscribers[chat_id]["last_sent"] = prediction
        save_state()
    return ok

# ---------------- Data source (simulated or real) ----------------
# sample simulated list (most recent first) - using the example you sent
SIMULATED_JSON = {
  "data": {
    "list": [
      {"issueNumber":"20251006100011135","number":"4"},
      {"issueNumber":"20251006100011134","number":"4"},
      {"issueNumber":"20251006100011133","number":"4"},
      {"issueNumber":"20251006100011132","number":"3"},
      {"issueNumber":"20251006100011131","number":"5"},
      {"issueNumber":"20251006100011130","number":"5"},
      {"issueNumber":"20251006100011129","number":"5"},
      {"issueNumber":"20251006100011128","number":"2"},
      {"issueNumber":"20251006100011127","number":"9"},
      {"issueNumber":"20251006100011126","number":"2"}
    ]
  }
}

def fetch_api_list():
    if USE_REAL_API:
        try:
            r = requests.get(API_URL, timeout=8)
            if r.status_code == 200:
                return r.json().get("data", {}).get("list", [])
            else:
                return []
        except Exception as e:
            print("[api] fetch error:", e)
            return []
    else:
        # return simulated copy (fresh copy each time)
        return list(SIMULATED_JSON["data"]["list"])

# ---------------- Adaptive predictor (same idea as before, compacted) ----------------
def find_pattern_candidates(seq_str):
    candidates = []
    n = len(seq_str)
    if n < 2:
        return candidates
    for w in ANAlYZE_WINDOW_SIZES_PLACEHOLDER:  # will be replaced below properly
        pass

# We'll implement predictive functions directly (cleaner)
def find_pattern_candidates_seq(seq_str):
    candidates = []
    n = len(seq_str)
    if n < 2:
        return candidates
    for w in ANALYZE_WINDOW_SIZES:
        if n <= w:
            continue
        pattern = seq_str[-w:]
        for i in range(0, n - w):
            if seq_str[i:i+w] == pattern:
                if i + w < n:
                    nxt = seq_str[i+w]
                    weight = w * (1 + (i / max(1, n)))
                    candidates.append((nxt, weight))
    return candidates

def adaptive_predict_from_seq(seq_str):
    if not seq_str:
        return None, 0
    candidates = find_pattern_candidates_seq(seq_str)
    if candidates:
        agg = defaultdict(float)
        for val,w in candidates:
            agg[val] += w
        total = sum(agg.values())
        if total <= 0:
            return None, 0
        probG = agg.get('G', 0.0)/total
        probP = agg.get('P', 0.0)/total
        # transition evidence
        last = seq_str[-1]
        trans_counts = {'G':0,'P':0}
        for i in range(len(seq_str)-1):
            if seq_str[i] == last:
                trans_counts[seq_str[i+1]] += 1
        trans_total = trans_counts['G'] + trans_counts['P']
        if trans_total > 0:
            tG = trans_counts['G']/trans_total
            tP = trans_counts['P']/trans_total
            probG = 0.7*probG + 0.3*tG
            probP = 0.7*probP + 0.3*tP
        s = probG + probP
        if s <= 0:
            return None, 0
        probG /= s; probP /= s
        # adjust by accuracy
        acc = stats.get("accuracy", 0.0)
        acc_factor = max(0.6, min(1.2, 1.0 + (acc - 50)/200))
        probG *= acc_factor; probP *= acc_factor
        s2 = probG + probP
        if s2 <= 0:
            return None, 0
        probG /= s2; probP /= s2
        return ('G', int(round(probG*100))) if probG>probP else ('P', int(round(probP*100)))
    # fallback: transition heuristic
    g_count = seq_str.count('G'); p_count = seq_str.count('P')
    if g_count + p_count == 0:
        return None, 0
    last = seq_str[-1]
    trans_counts = {'G':0,'P':0}
    for i in range(len(seq_str)-1):
        if seq_str[i] == last:
            trans_counts[seq_str[i+1]] += 1
    trans_total = trans_counts['G'] + trans_counts['P']
    if trans_total > 0:
        pred = 'G' if trans_counts['G'] > trans_counts['P'] else 'P'
        conf = int(round((max(trans_counts['G'], trans_counts['P'])/trans_total)*60))
        return pred, conf
    # frequency revert
    if g_count > p_count:
        return 'P', int(round((g_count/(g_count+p_count))*40))
    elif p_count > g_count:
        return 'G', int(round((p_count/(g_count+p_count))*40))
    else:
        return ('G' if int(time.time())%2==0 else 'P'), 20

# wrapper to get current prediction
def current_prediction_payload():
    seq = ''.join(gp_history[-LOOKBACK_MAX:]) if gp_history else ""
    pred, conf = adaptive_predict_from_seq(seq)
    # next_issue calculation
    next_issue = None
    if last_issue:
        try:
            next_issue = str(int(last_issue) + 1)
        except:
            next_issue = (last_issue or "") + "+1"
    return pred, conf, next_issue

# ---------------- Main loop: fetch -> predict -> send ----------------
def update_history_from_api_and_predict():
    global last_issue
    while True:
        try:
            lst = fetch_api_list()
            if lst:
                # API returns newest-first -> we will process accordingly
                # take first N then reverse to chronological
                take = min(len(lst), LOOKBACK_MAX)
                items = list(reversed(lst[:take]))
                added_new = False
                for item in items:
                    try:
                        n = int(item.get("number", item.get("num", 0)))
                    except:
                        continue
                    issue = item.get("issueNumber") or item.get("issue") or None
                    # append if new
                    if not numeric_history or (issue and issue != last_issue):
                        numeric_history.append(n)
                        gp_history.append('G' if n >= 5 else 'P')
                        last_issue = issue or last_issue
                        added_new = True
                # trim
                if len(numeric_history) > LOOKBACK_MAX:
                    del numeric_history[0: len(numeric_history)-LOOKBACK_MAX]
                    del gp_history[0: len(gp_history)-LOOKBACK_MAX]
                # if new actuals arrived, evaluate last pending signal:
                if added_new and signals:
                    # evaluate last
                    last_sig = signals[-1]
                    if not last_sig.get("evaluated"):
                        actual = gp_history[-1]
                        last_sig["actual"] = actual
                        last_sig["evaluated"] = True
                        last_sig["correct"] = (last_sig["prediction"] == actual)
                        # update stats
                        stats["total"] += 1
                        if last_sig["correct"]:
                            stats["correct"] += 1
                        stats["accuracy"] = round((stats["correct"]/stats["total"])*100, 2) if stats["total"]>0 else 0.0
                        save_state()
                # predict next
                pred, conf, next_issue = current_prediction_payload()
                # create a pending signal object
                sig = {"ts": int(time.time()), "prediction": pred, "confidence": conf, "next_issue": next_issue, "actual": None, "evaluated": False, "correct": None}
                signals.append(sig)
                # send to subscribers but only if differs from last_sent
                for chat_id in list(subscribers.keys()):
                    try:
                        send_prediction_to_chat(chat_id, pred, conf, next_issue)
                    except Exception as e:
                        print("[send] error to", chat_id, e)
                save_state()
        except Exception as e:
            print("[main loop] error:", e)
        time.sleep(FETCH_INTERVAL)

# -------------- Initialization & run --------------
def start_all():
    load_state()
    # start telegram updates loop
    t1 = threading.Thread(target=telegram_updates_loop, daemon=True)
    t1.start()
    # start main fetch/predict/send loop
    t2 = threading.Thread(target=update_history_from_api_and_predict, daemon=True)
    t2.start()
    print("Bot IA POPBRA iniciado. Aguarde e envie /start no seu bot para receber sinais.")
    # keep main thread alive
    while True:
        time.sleep(60)

if __name__ == "__main__":
    # small fix: ensure ANALYZE_WINDOW_SIZES exists; also import missing names used in functions
    from collections import defaultdict
    # start
    start_all()
